{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 120126,
          "databundleVersionId": 14369730,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nipunagarwal9636/Grammar-Scoring-engine/blob/main/Grammar_Scoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "ljfNuZ5Sus90"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "shl_intern_hiring_assessment_2025_path = kagglehub.competition_download('shl-intern-hiring-assessment-2025')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "JXR__Xaaus9_"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q lightgbm librosa sentence-transformers"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-11T08:30:06.546966Z",
          "iopub.execute_input": "2025-11-11T08:30:06.547397Z",
          "iopub.status.idle": "2025-11-11T08:30:11.324883Z",
          "shell.execute_reply.started": "2025-11-11T08:30:06.547355Z",
          "shell.execute_reply": "2025-11-11T08:30:11.323459Z"
        },
        "id": "GozkDhCnus-A",
        "outputId": "dd46f489-c8f2-4a24-c95d-a3dc6dfca9c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pandas as pd\n",
        "DATA_DIR = '/kaggle/input/shl-intern-hiring-assessment-2025/dataset'\n",
        "OUTPUT_DIR = '/kaggle/working'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print('DATA_DIR =', DATA_DIR)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-11T08:30:11.327198Z",
          "iopub.execute_input": "2025-11-11T08:30:11.327497Z",
          "iopub.status.idle": "2025-11-11T08:30:11.333992Z",
          "shell.execute_reply.started": "2025-11-11T08:30:11.327467Z",
          "shell.execute_reply": "2025-11-11T08:30:11.333155Z"
        },
        "id": "D-2jzx8tus-C",
        "outputId": "f196c77e-fa13-44c3-a379-80abf5327ca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "DATA_DIR = /kaggle/input/shl-intern-hiring-assessment-2025/dataset\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "csvs = list(Path(DATA_DIR).rglob('*.csv'))\n",
        "print('Found CSVs:', [p.name for p in csvs])\n",
        "train_df = pd.read_csv(csvs[0]) if csvs else None\n",
        "test_df  = pd.read_csv(csvs[1]) if len(csvs) > 1 else None\n",
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-11T08:30:11.335172Z",
          "iopub.execute_input": "2025-11-11T08:30:11.335596Z",
          "iopub.status.idle": "2025-11-11T08:30:12.40645Z",
          "shell.execute_reply.started": "2025-11-11T08:30:11.335566Z",
          "shell.execute_reply": "2025-11-11T08:30:12.405563Z"
        },
        "id": "kj8qAZhfus-D",
        "outputId": "829dfe35-af6c-405d-eec8-b39b6cfbbe10"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Found CSVs: ['train.csv', 'test.csv']\n",
          "output_type": "stream"
        },
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "    filename  label\n0  audio_173    3.0\n1  audio_138    3.0\n2  audio_127    2.0\n3   audio_95    2.0\n4   audio_73    3.5",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_173</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_138</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_127</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_95</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_73</td>\n      <td>3.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text_cols = [c for c in train_df.columns if train_df[c].dtype == 'object']\n",
        "label_col = next((c for c in ['target','score','label','y','grammar_score'] if c in train_df.columns), None)\n",
        "print('Text cols:', text_cols)\n",
        "print('Label col:', label_col)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-11T08:30:12.408409Z",
          "iopub.execute_input": "2025-11-11T08:30:12.408775Z",
          "iopub.status.idle": "2025-11-11T08:30:12.415263Z",
          "shell.execute_reply.started": "2025-11-11T08:30:12.408751Z",
          "shell.execute_reply": "2025-11-11T08:30:12.414297Z"
        },
        "id": "Zod4rWw6us-E",
        "outputId": "336bc14e-d37b-4659-f84e-875e345ab277"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Text cols: ['filename']\nLabel col: label\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def add_text_feats(df, text_col):\n",
        "    s = df[text_col].fillna('').astype(str)\n",
        "    df[text_col+'_len'] = s.str.len()\n",
        "    df[text_col+'_words'] = s.str.split().apply(len)\n",
        "    return df\n",
        "\n",
        "for tc in text_cols:\n",
        "    train_df = add_text_feats(train_df, tc)\n",
        "    if test_df is not None and tc in test_df.columns:\n",
        "        test_df = add_text_feats(test_df, tc)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-11T08:30:12.416242Z",
          "iopub.execute_input": "2025-11-11T08:30:12.416553Z",
          "iopub.status.idle": "2025-11-11T08:30:12.441277Z",
          "shell.execute_reply.started": "2025-11-11T08:30:12.416523Z",
          "shell.execute_reply": "2025-11-11T08:30:12.440229Z"
        },
        "id": "btTQ1e3uus-F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "N_EMB = 4\n",
        "for tc in text_cols:\n",
        "    tr_emb = embed_model.encode(train_df[tc].fillna('').tolist(), show_progress_bar=True)[:,:N_EMB]\n",
        "    for i in range(N_EMB): train_df[f'{tc}_emb_{i}'] = tr_emb[:,i]\n",
        "    if test_df is not None:\n",
        "        te_emb = embed_model.encode(test_df[tc].fillna('').tolist(), show_progress_bar=True)[:,:N_EMB]\n",
        "        for i in range(N_EMB): test_df[f'{tc}_emb_{i}'] = te_emb[:,i]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-11T08:30:12.442326Z",
          "iopub.execute_input": "2025-11-11T08:30:12.442644Z",
          "iopub.status.idle": "2025-11-11T08:30:15.086107Z",
          "shell.execute_reply.started": "2025-11-11T08:30:12.442613Z",
          "shell.execute_reply": "2025-11-11T08:30:15.085313Z"
        },
        "id": "UHQDMwq4us-G",
        "outputId": "61b8308b-ab63-4762-df50-149125c65baf",
        "colab": {
          "referenced_widgets": [
            "416b9580c7aa42fe95f34ee0f1fe3611",
            "391a29934b894642bf0de29f402d6cb8"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/13 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "416b9580c7aa42fe95f34ee0f1fe3611"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/7 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "391a29934b894642bf0de29f402d6cb8"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa, numpy as np\n",
        "from tqdm import tqdm\n",
        "audio_col = next((c for c in ['audio_path','file_path','wav'] if c in train_df.columns), None)\n",
        "def extract_audio_feats(path):\n",
        "    try:\n",
        "        y, sr = librosa.load(Path(DATA_DIR)/path, sr=16000)\n",
        "        return pd.Series({'duration': librosa.get_duration(y=y, sr=sr), 'rms': librosa.feature.rms(y=y).mean()})\n",
        "    except: return pd.Series({'duration': np.nan, 'rms': np.nan})\n",
        "if audio_col:\n",
        "    train_df = pd.concat([train_df, train_df[audio_col].progress_apply(extract_audio_feats)], axis=1)\n",
        "    if test_df is not None:\n",
        "        test_df = pd.concat([test_df, test_df[audio_col].progress_apply(extract_audio_feats)], axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-11T08:30:15.087121Z",
          "iopub.execute_input": "2025-11-11T08:30:15.087771Z",
          "iopub.status.idle": "2025-11-11T08:30:15.094402Z",
          "shell.execute_reply.started": "2025-11-11T08:30:15.087738Z",
          "shell.execute_reply": "2025-11-11T08:30:15.093596Z"
        },
        "id": "3GjHOdLPus-H"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "feat_cols = [c for c in train_df.columns if any(x in c for x in ['_len','_words','_emb_','duration','rms'])]\n",
        "X = train_df[feat_cols].fillna(0)\n",
        "y = train_df[label_col]\n",
        "X_test = test_df[feat_cols].fillna(0) if test_df is not None else None\n",
        "\n",
        "models, oof = [], np.zeros(len(X))\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (tr, val) in enumerate(kf.split(X)):\n",
        "    print(f\"Fold {fold+1}\")\n",
        "    m = lgb.LGBMRegressor(n_estimators=300, learning_rate=0.1, num_leaves=31)\n",
        "    m.fit(\n",
        "        X.iloc[tr], y.iloc[tr],\n",
        "        eval_set=[(X.iloc[val], y.iloc[val])],\n",
        "        eval_metric='rmse',\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=30), lgb.log_evaluation(50)]\n",
        "    )\n",
        "    oof[val] = m.predict(X.iloc[val])\n",
        "    models.append(m)\n",
        "\n",
        "print(\"OOF RMSE:\", mean_squared_error(y, oof, squared=False))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-11T08:30:15.095045Z",
          "iopub.execute_input": "2025-11-11T08:30:15.095261Z",
          "iopub.status.idle": "2025-11-11T08:30:15.180569Z",
          "shell.execute_reply.started": "2025-11-11T08:30:15.095242Z",
          "shell.execute_reply": "2025-11-11T08:30:15.179524Z"
        },
        "id": "vrS1y7y2us-I",
        "outputId": "4f777fcf-d3c3-4f9f-e397-4f4f7d205c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Fold 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000091 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 370\n[LightGBM] [Info] Number of data points in the train set: 272, number of used features: 5\n[LightGBM] [Info] Start training from score 2.893382\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 30 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[1]\tvalid_0's rmse: 0.764614\tvalid_0's l2: 0.584634\nFold 2\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 374\n[LightGBM] [Info] Number of data points in the train set: 273, number of used features: 5\n[LightGBM] [Info] Start training from score 2.906593\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 30 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[1]\tvalid_0's rmse: 0.801917\tvalid_0's l2: 0.643071\nFold 3\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000042 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 374\n[LightGBM] [Info] Number of data points in the train set: 273, number of used features: 5\n[LightGBM] [Info] Start training from score 2.932234\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 30 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[3]\tvalid_0's rmse: 0.733815\tvalid_0's l2: 0.538485\nOOF RMSE: 0.7672808657162037\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "if X_test is not None:\n",
        "    preds = np.mean([m.predict(X_test) for m in models], axis=0)\n",
        "\n",
        "\n",
        "    if 'filename' in test_df.columns:\n",
        "        submission = pd.DataFrame({\n",
        "            'filename': test_df['filename'],\n",
        "            'label': preds\n",
        "        })\n",
        "    else:\n",
        "\n",
        "        possible_ids = [c for c in test_df.columns if 'file' in c.lower()]\n",
        "        id_col = possible_ids[0] if possible_ids else test_df.columns[0]\n",
        "        print(f\"⚠️ 'filename' column not found; using '{id_col}' as ID.\")\n",
        "        submission = pd.DataFrame({\n",
        "            'filename': test_df[id_col],\n",
        "            'label': preds\n",
        "        })\n",
        "\n",
        "\n",
        "    sub_path = os.path.join(OUTPUT_DIR, \"submission.csv\")\n",
        "    submission.to_csv(sub_path, index=False)\n",
        "    print(f\"✅ submission.csv saved successfully at: {sub_path}\")\n",
        "    print(submission.head())\n",
        "\n",
        "else:\n",
        "    print(\"❌ No test set found; skipping submission.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-11T08:38:17.637228Z",
          "iopub.execute_input": "2025-11-11T08:38:17.637546Z",
          "iopub.status.idle": "2025-11-11T08:38:17.6581Z",
          "shell.execute_reply.started": "2025-11-11T08:38:17.637514Z",
          "shell.execute_reply": "2025-11-11T08:38:17.656891Z"
        },
        "id": "_anFrBwwus-I",
        "outputId": "56f2fdde-7096-486c-e351-15b0e725b3cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "✅ submission.csv saved successfully at: /kaggle/working/submission.csv\n    filename     label\n0  audio_141  2.901584\n1  audio_114  2.886334\n2   audio_17  2.931496\n3   audio_76  2.928373\n4  audio_156  2.893446\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "0XY74vkHus-J"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data= pd.read_csv(\"/kaggle/working/submission.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-11T08:38:34.030762Z",
          "iopub.execute_input": "2025-11-11T08:38:34.031106Z",
          "iopub.status.idle": "2025-11-11T08:38:34.042766Z",
          "shell.execute_reply.started": "2025-11-11T08:38:34.031079Z",
          "shell.execute_reply": "2025-11-11T08:38:34.041995Z"
        },
        "id": "09wnhEr3us-K",
        "outputId": "7aafdcd2-2f81-4112-803a-5b1572ec3a61"
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "    filename     label\n0  audio_141  2.901584\n1  audio_114  2.886334\n2   audio_17  2.931496\n3   audio_76  2.928373\n4  audio_156  2.893446",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_141</td>\n      <td>2.901584</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_114</td>\n      <td>2.886334</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_17</td>\n      <td>2.931496</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_76</td>\n      <td>2.928373</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_156</td>\n      <td>2.893446</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "kng0gjnbus-K"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}